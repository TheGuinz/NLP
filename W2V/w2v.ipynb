{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval using word2vec based Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "sys.path.insert(0, '/home/guinzburg/NLP/Data')\n",
    "from data_parser import parse_queries, parse_documents\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy ## for stopwords removal\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner','parser'])\n",
    "nlp.max_length=5000000\n",
    "from gensim.models import Word2Vec # for word2vec model\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the files containing queries and documents using 'parse_queries' and 'parse_documents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all queries\n",
    "queries = pd.DataFrame.from_dict(parse_queries(path='/home/guinzburg/NLP/Data/CISI.QRY'), columns = ['query'], orient=\"index\").reset_index(drop=True)\n",
    "queries.index.name = 'id'\n",
    "\n",
    "# Get all documents\n",
    "documents = pd.DataFrame.from_dict(parse_documents(path='/home/guinzburg/NLP/Data/CISI.ALL'), orient=\"index\").reset_index(drop=True)\n",
    "documents.index.name = 'id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a train set and test set for training the word2vec model for both queries and documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test set for queries (80% / 20%)\n",
    "training_queries, testing_queries = train_test_split(queries, test_size=0.2)\n",
    "\n",
    "# Create train and test set for documents (80% / 20%)\n",
    "training_documents, testing_documents = train_test_split(documents, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "Process the documents and queries as follows:\n",
    "\n",
    "### Documents:\n",
    "1. Lowercase the text\n",
    "2. Expand Contractions\n",
    "3. Clean the text\n",
    "4. Remove Stopwords\n",
    "5. Lemmatize words\n",
    "\n",
    "### Queries:\n",
    "1. Lowercase the text\n",
    "2. Expand Contractions\n",
    "3. Clean the text\n",
    "4. We now have everything clear in our minds, so let’s start writing codes for pre-processing the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty corpuses dataframes for training and testing\n",
    "training_corpus = pd.DataFrame(columns=['cleaned','lemmatized', 'vector'])\n",
    "testing_corpus = pd.DataFrame(columns=['cleaned','lemmatized', 'vector'])\n",
    "\n",
    "# Lowercasing the text\n",
    "training_corpus['cleaned'] = training_documents['body'].apply(lambda x:x.lower())\n",
    "testing_corpus['cleaned'] = testing_documents['body'].apply(lambda x:x.lower())\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    \"\"\"\n",
    "        Description: function for expanding contractions in a given text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary of english Contractions\n",
    "    contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\"can't\": \"can not\",\"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\"i'll\": \"i will\",\"i'll've\": \"i will have\",\"i'm\": \"i am\",\"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\n",
    "    \"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\n",
    "    \"there'd\": \"there would\",\"there'd've\": \"there would have\",\n",
    "    \"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\n",
    "    \"what've\": \"what have\",\"when've\": \"when have\",\"where'd\": \"where did\",\n",
    "    \"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "    \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\"you'd've\": \"you would have\",\"you'll\": \"you will\",\"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\"you've\": \"you have\"}\n",
    "\n",
    "    # Regular expression for finding contractions\n",
    "    contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    \n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        Description: function for cleaning a given text, \n",
    "        such as: \n",
    "        [*] remove the words with digits\n",
    "        [*] replace newline characters with space\n",
    "        [*] remove URLs\n",
    "        [*] replace everything that isn’t English alphabets with space\n",
    "    \"\"\"\n",
    "    \n",
    "    text = re.sub('\\w*\\d\\w*','', text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub('[^a-z]',' ',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Expanding Contractions\n",
    "training_corpus['cleaned'] = training_corpus['cleaned'].apply(lambda x:expand_contractions(x))\n",
    "testing_corpus['cleaned'] = testing_corpus['cleaned'].apply(lambda x:expand_contractions(x))\n",
    "\n",
    "# Cleaning corpus using RegEx\n",
    "training_corpus['cleaned'] = training_corpus['cleaned'].apply(lambda x: clean_text(x))\n",
    "testing_corpus['cleaned'] = testing_corpus['cleaned'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Removing extra spaces\n",
    "training_corpus['cleaned'] = training_corpus['cleaned'].apply(lambda x: re.sub(' +',' ',x))\n",
    "testing_corpus['cleaned'] = testing_corpus['cleaned'].apply(lambda x: re.sub(' +',' ',x))\n",
    "\n",
    "# Removing Stopwords and Lemmatizing words\n",
    "training_corpus['lemmatized'] = training_corpus['cleaned'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))\n",
    "testing_corpus['lemmatized'] = testing_corpus['cleaned'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rre-process queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframes for queries training and testing\n",
    "training_queries_ = pd.DataFrame(columns=['cleaned','lemmatized', 'vector'])\n",
    "testing_queries_ = pd.DataFrame(columns=['cleaned','lemmatized', 'vector'])\n",
    "\n",
    "# Lowercasing the text\n",
    "training_queries_['cleaned'] = training_queries['query'].apply(lambda x:x.lower())\n",
    "testing_queries_['cleaned'] = testing_queries['query'].apply(lambda x:x.lower())\n",
    "\n",
    "# Expanding contractions\n",
    "training_queries_['cleaned'] = training_queries_['cleaned'].apply(lambda x:expand_contractions(x))\n",
    "testing_queries_['cleaned'] = testing_queries_['cleaned'].apply(lambda x:expand_contractions(x))\n",
    "\n",
    "# Cleaning queries using RegEx\n",
    "training_queries_['cleaned'] = training_queries_['cleaned'].apply(lambda x: clean_text(x))\n",
    "testing_queries_['cleaned'] = testing_queries_['cleaned'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Removing extra spaces\n",
    "training_queries_['cleaned'] = training_queries_['cleaned'].apply(lambda x: re.sub(' +',' ',x))\n",
    "testing_queries_['cleaned'] = testing_queries_['cleaned'].apply(lambda x: re.sub(' +',' ',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vectors\n",
    "Train the word2vec model and generate vectors for documents and queries in the testing set for information retrieval. First step is to prepare the dataset for training the model, and to use the same w2v model for generating vectors for both documents and queries,  we’ll combine both documents and queries training to create a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining corpus and queries for training\n",
    "combined_training = pd.concat([training_corpus.rename(columns={'lemmatized':'text'})['text'],\\\n",
    "                                 training_queries_.rename(columns={'cleaned':'text'})['text']]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Using Gensim to train the word2vec model. Gensim is a python package used for topic modeling, text processing, and working with word vector models such as Word2Vec and FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4068\n",
      "Model vector size: 100\n"
     ]
    }
   ],
   "source": [
    "# Creating data for the model training, iterate on each row from the combined data and split it in to words\n",
    "train_data = []\n",
    "for row in combined_training:\n",
    "    train_data.append(row.split())\n",
    "\n",
    "# Training a word2vec model from the given data set\n",
    "# w2v_model = Word2Vec(train_data, vector_size=300, min_count=2, window=5, sg=1, workers=4)\n",
    "# vector_size: default value 100 [https://stackoverflow.com/questions/45444964/python-what-is-the-size-parameter-in-gensim-word2vec-model-class]\n",
    "# min_count: Words below the min_count frequency are dropped before training occurs. \n",
    "# window: [https://stackoverflow.com/questions/22272370/word2vec-effect-of-window-size-used/30447723#30447723]\n",
    "w2v_model = Word2Vec(train_data, min_count=2)\n",
    "print('Vocabulary size:', len(w2v_model.wv.index_to_key))\n",
    "print('Model vector size:', w2v_model.wv.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_w2v(doc_tokens):\n",
    "    \"\"\"\n",
    "    Description: function for generating vectors for the whole document or query. \n",
    "    This function will use the word2vec model and generate the vectors for each word in the document.\n",
    "    Then, it will take the average of the vectors, and the resulting vector will represent the vector for the document. \n",
    "    Any document or query of length zero will have a vector containing zeroes, and any word which won’t be present in the vocabulary will have a vector with random values.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    if len(doc_tokens) < 1:\n",
    "        # w2v_model.wv.vector_size: 100 (default)\n",
    "        return np.zeros(w2v_model.wv.vector_size)\n",
    "    else:\n",
    "        for tok in doc_tokens:\n",
    "            if tok in list(w2v_model.wv.index_to_key):\n",
    "                embeddings.append(w2v_model.wv.get_vector(tok))\n",
    "            else:\n",
    "                # w2v_model.wv.vector_size: 100 (default)\n",
    "                embeddings.append(np.random.rand(w2v_model.wv.vector_size))\n",
    "    \n",
    "        # mean the vectors of individual words to get the vector of the document\n",
    "        return np.mean(embeddings, axis=0)\n",
    "\n",
    "# Getting Word2Vec Vectors for Testing Corpus and Queries\n",
    "testing_corpus['vector'] = testing_corpus['lemmatized'].apply(lambda x :get_embedding_w2v(x.split()))\n",
    "testing_queries_['vector'] = testing_queries_['cleaned'].apply(lambda x :get_embedding_w2v(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final IR Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_ir(query):\n",
    "    \"\"\"\n",
    "        Description: a function that takes a query as an input and return the top 10 relevant documents. \n",
    "        This function will follow the information retrieval(IR) pipeline. First, it will pre-process the query. Then, it will generate the vector for it. After that, it will rank the documents based on the similarity scores.\n",
    "    \"\"\"      \n",
    "    # pre-process Query\n",
    "    query = re.sub(' +', ' ', clean_text(expand_contractions(query.lower())))\n",
    "\n",
    "    # generating vector\n",
    "    vector = get_embedding_w2v(query.split())\n",
    "\n",
    "    # ranking documents\n",
    "    documents_ = documents[['title','body']].copy()\n",
    "    documents['similarity'] = testing_corpus['vector'].apply(lambda x: cosine_similarity(np.array(vector).reshape(1, -1),np.array(x).reshape(1, -1)).item())\n",
    "    documents.sort_values(by='similarity', ascending=False,inplace=True)\n",
    "\n",
    "    return documents.head(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Retrieval Systems: Specifics and Problems</td>\n",
       "      <td>The essential differences between data retriev...</td>\n",
       "      <td>0.973983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project Intrex: A General Review</td>\n",
       "      <td>A comprehensive review of the experimental inf...</td>\n",
       "      <td>0.971820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Test for the Separation of Relevant and Non-...</td>\n",
       "      <td>Many retrieval experiments are intended to dis...</td>\n",
       "      <td>0.971063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vocabulary Building and Control Techniques</td>\n",
       "      <td>The rationale is given for creation and mainta...</td>\n",
       "      <td>0.970813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Representation of Concept Relations Using the ...</td>\n",
       "      <td>Successful information retrieval from a mechan...</td>\n",
       "      <td>0.970574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The CA Integrated Subject File. II. Evaluation...</td>\n",
       "      <td>The relative retrieval performances of the CA ...</td>\n",
       "      <td>0.970516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The identification of variable-length, equifre...</td>\n",
       "      <td>The words of natural language texts exhibit a ...</td>\n",
       "      <td>0.969469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Business Intelligence System</td>\n",
       "      <td>An automatic system is being developed to diss...</td>\n",
       "      <td>0.969383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>An Experiment in Index Term Frequency</td>\n",
       "      <td>This paper presents an experimental study of i...</td>\n",
       "      <td>0.969079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Minimum Vocabularies in Information Indexing</td>\n",
       "      <td>Words have no precision, though in information...</td>\n",
       "      <td>0.969029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0     Data Retrieval Systems: Specifics and Problems   \n",
       "1                   Project Intrex: A General Review   \n",
       "2  A Test for the Separation of Relevant and Non-...   \n",
       "3         Vocabulary Building and Control Techniques   \n",
       "4  Representation of Concept Relations Using the ...   \n",
       "5  The CA Integrated Subject File. II. Evaluation...   \n",
       "6  The identification of variable-length, equifre...   \n",
       "7                     A Business Intelligence System   \n",
       "8              An Experiment in Index Term Frequency   \n",
       "9       Minimum Vocabularies in Information Indexing   \n",
       "\n",
       "                                                body  similarity  \n",
       "0  The essential differences between data retriev...    0.973983  \n",
       "1  A comprehensive review of the experimental inf...    0.971820  \n",
       "2  Many retrieval experiments are intended to dis...    0.971063  \n",
       "3  The rationale is given for creation and mainta...    0.970813  \n",
       "4  Successful information retrieval from a mechan...    0.970574  \n",
       "5  The relative retrieval performances of the CA ...    0.970516  \n",
       "6  The words of natural language texts exhibit a ...    0.969469  \n",
       "7  An automatic system is being developed to diss...    0.969383  \n",
       "8  This paper presents an experimental study of i...    0.969079  \n",
       "9  Words have no precision, though in information...    0.969029  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_ir(\"\"\"How can actually pertinent data, as opposed to references or entire articles\n",
    "themselves, be retrieved automatically in response to information requests?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking & Evaluation\n",
    "\n",
    "We have successfully trained our word2vec model and created vectors for documents and queries in the testing set for information retrieval. Now, it’s time to rank the documents according to the queries. But before that, we need to learn about the evaluation metric. Because only implementing a method won’t solve our purpose. We need a metric for checking the performance of our model.\n",
    "\n",
    "The evaluation metric which we’ll be using here is Mean Average Precision(MAP@K)\n",
    "Mean Average Precision is the mean of the average precision for all the queries used during evaluation. So, precision is calculated at each rank, average precision is calculated for a query, and mean average precision is calculated for the whole IR model. Now you know what MAP@K is. So, let’s write some code and calculate it for our vector space model.\n",
    "\n",
    "For the ranking and evaluation, I have created a function average_precision(), which takes the query id and vector of a query as an input and returns the average precision value.\n",
    "The value of MAP ranges between 0 and 1, with zero being the worst and one as best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function for calculating average precision for a query\n",
    "def average_precision(qid,qvector):\n",
    "  \n",
    "  # Getting the ground truth and document vectors\n",
    "  qresult=testing_result.loc[testing_result['qid']==qid,['docid','rel']]\n",
    "  qcorpus=testing_corpus.loc[testing_corpus['docid'].isin(qresult['docid']),['docid','vector']]\n",
    "  qresult=pd.merge(qresult,qcorpus,on='docid')\n",
    "  \n",
    "  # Ranking documents for the query\n",
    "  qresult['similarity']=qresult['vector'].apply(lambda x: cosine_similarity(np.array(qvector).reshape(1, -1),np.array(x).reshape(1, -1)).item())\n",
    "  qresult.sort_values(by='similarity',ascending=False,inplace=True)\n",
    "\n",
    "  # Taking Top 10 documents for the evaluation\n",
    "  ranking=qresult.head(10)['rel'].values\n",
    "  \n",
    "  # Calculating precision\n",
    "  precision=[]\n",
    "  for i in range(1,11):\n",
    "    if ranking[i-1]:\n",
    "      precision.append(np.sum(ranking[:i])/i)\n",
    "  \n",
    "  # If no relevant document in list then return 0\n",
    "  if precision==[]:\n",
    "    return 0\n",
    "\n",
    "  return np.mean(precision)\n",
    "\n",
    "# Calculating average precision for all queries in the test set\n",
    "testing_queries['AP']=testing_queries.apply(lambda x: average_precision(x['qid'],x['vector']),axis=1)\n",
    "\n",
    "# Finding Mean Average Precision\n",
    "print('Mean Average Precision=>',testing_queries['AP'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
